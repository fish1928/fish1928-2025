{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import BoolTensor\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBertClassifier(torch.nn.Module):\n",
    "\n",
    "    DEFAULT_FILENAME_CLASSIFIER = '.model.json'\n",
    "    DEFAULT_FILENAME_BERT = 'bert_config.json'\n",
    "    DEFAULT_FILENAME_MODEL = 'model.pt'\n",
    "    DEFAULT_KEYS_IGNORED_CLASSIFIER = ['metrics', 'allmetrics']\n",
    "\n",
    "    def __init__(self, path_folder_model=None):\n",
    "        super(SimpleBertClassifier, self).__init__()\n",
    "\n",
    "        filename_config_classifier = self.__class__.DEFAULT_FILENAME_CLASSIFIER\n",
    "        filename_config_bert = self.__class__.DEFAULT_FILENAME_BERT\n",
    "        filename_model = self.__class__.DEFAULT_FILENAME_MODEL\n",
    "        keys_ignored_classifier = self .__class__.DEFAULT_KEYS_IGNORED_CLASSIFIER\n",
    "\n",
    "\n",
    "        self.path_folder_model = path_folder_model\n",
    "        self.path_config_bert = os.path.join(path_folder_model, filename_config_bert)\n",
    "        self.path_config_classifier = os.path.join(path_folder_model, filename_config_classifier)\n",
    "        self.path_file_model = os.path.join(path_folder_model, filename_model)\n",
    "\n",
    "        with open(self.path_config_classifier, 'r') as file:\n",
    "            self.config_classifier = json.load(file)\n",
    "        # end\n",
    "\n",
    "        for key in keys_ignored_classifier:\n",
    "            if key in self.config_classifier:\n",
    "                del(self.config_classifier[key])\n",
    "            # end\n",
    "        # end\n",
    "\n",
    "        # classfier parameters\n",
    "        self.classifier_input_size = self.config_classifier.get('bert').get('input_size')\n",
    "        self.classifier_max_length = self.config_classifier.get('bert').get('max_length')\n",
    "        self.classifier_output_size = self.config_classifier.get('bert').get('output_size')\n",
    "\n",
    "        self.labels_output_classifier = self.config_classifier.get('classes')\n",
    "        self.dict_label_index = {label: index for index, label in enumerate(self.labels_output_classifier)}\n",
    "        self.num_labels = len(self.dict_label_index)\n",
    "        # classifier parameters done\n",
    "\n",
    "        self.config_l1 = None\n",
    "        self.l1 = None\n",
    "        self.linear = None\n",
    "\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.loaded = False\n",
    "\n",
    "        self.func_loss = None\n",
    "    # end\n",
    "\n",
    "\n",
    "    def load(self, is_eval=True):\n",
    "        if not self.loaded:\n",
    "            self.config_l1 = BertConfig.from_pretrained(self.path_config_bert)\n",
    "            self.l1 = BertModel(self.config_l1)\n",
    "            self.classifier = torch.nn.Linear(self.classifier_input_size, self.classifier_output_size)\n",
    "            \n",
    "            self.load_state_dict(torch.load(self.path_file_model, map_location=torch.device(self.device)))\n",
    "            self.tokenizer = BertTokenizer.from_pretrained(self.path_folder_model)\n",
    "             \n",
    "            if is_eval:\n",
    "                self.eval()\n",
    "            else:\n",
    "                self.func_loss = torch.nn.CrossEntropyLoss()\n",
    "                self.train()\n",
    "            # end\n",
    "            self.loaded = True\n",
    "        return self\n",
    "    # end\n",
    "\n",
    "    \n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None):\n",
    "        output_bert = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_bert[0]\n",
    "        pooler = hidden_state[:, 0, :]  # only take the CLS one\n",
    "        output = self.classifier(pooler)\n",
    "\n",
    "        if labels is None:\n",
    "            return output\n",
    "        # end\n",
    "\n",
    "        loss = self.func_loss(output.view(-1, self.num_labels), labels.view(-1))\n",
    "        return (loss, output)\n",
    "    # end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 loaded\n"
     ]
    }
   ],
   "source": [
    "path_model_1 = os.path.join('models', 'bert', 'target_v1')\n",
    "model_1 = SimpleBertClassifier(path_model_1)\n",
    "model_1.load(is_eval=False)\n",
    "print('model 1 loaded')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicts(model, samples_input):\n",
    "    tokenizer = model.tokenizer\n",
    "\n",
    "    # end\n",
    "    outputs_raw = []\n",
    "    for sample_input in samples_input:\n",
    "        sentence = ' '.join(sample_input.split())\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            sentence, None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        for key in inputs:\n",
    "            inputs[key].to(model.device)\n",
    "        # end\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_raw = model(**inputs).cpu().numpy().flatten().tolist()\n",
    "            # print('jinyuj: predicts:83 output_raw: {}'.format(output_raw))\n",
    "            outputs_raw.append(output_raw)\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    info_result = {\n",
    "        'outputs': outputs_raw,\n",
    "        'labels': model.labels_output_classifier\n",
    "    }\n",
    "\n",
    "    return info_result\n",
    "# end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.6816844344139099,\n",
       " 0.5647275447845459,\n",
       " -0.896682858467102,\n",
       " -0.8525747060775757,\n",
       " 3.626321315765381,\n",
       " -2.5834715366363525,\n",
       " -0.15418574213981628]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts(model_1, \"hello world\")['outputs'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
