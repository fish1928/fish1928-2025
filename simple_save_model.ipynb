{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import BoolTensor\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBertClassifier(torch.nn.Module):\n",
    "\n",
    "    DEFAULT_FILENAME_CLASSIFIER = '.model.json'\n",
    "    DEFAULT_FILENAME_BERT = 'bert_config.json'\n",
    "    DEFAULT_FILENAME_MODEL = 'model.pt'\n",
    "    DEFAULT_KEYS_IGNORED_CLASSIFIER = ['metrics', 'allmetrics']\n",
    "\n",
    "    def __init__(self, path_folder_model=None):\n",
    "        super(SimpleBertClassifier, self).__init__()\n",
    "\n",
    "        filename_config_classifier = self.__class__.DEFAULT_FILENAME_CLASSIFIER\n",
    "        filename_config_bert = self.__class__.DEFAULT_FILENAME_BERT\n",
    "        filename_model = self.__class__.DEFAULT_FILENAME_MODEL\n",
    "        keys_ignored_classifier = self .__class__.DEFAULT_KEYS_IGNORED_CLASSIFIER\n",
    "\n",
    "\n",
    "        self.path_folder_model = path_folder_model\n",
    "        self.path_config_bert = os.path.join(path_folder_model, filename_config_bert)\n",
    "        self.path_config_classifier = os.path.join(path_folder_model, filename_config_classifier)\n",
    "        self.path_file_model = os.path.join(path_folder_model, filename_model)\n",
    "\n",
    "        with open(self.path_config_classifier, 'r') as file:\n",
    "            self.config_classifier = json.load(file)\n",
    "        # end\n",
    "\n",
    "        for key in keys_ignored_classifier:\n",
    "            if key in self.config_classifier:\n",
    "                del(self.config_classifier[key])\n",
    "            # end\n",
    "        # end\n",
    "\n",
    "        # classfier parameters\n",
    "        self.classifier_input_size = self.config_classifier.get('bert').get('input_size')\n",
    "        self.classifier_max_length = self.config_classifier.get('bert').get('max_length')\n",
    "        self.classifier_output_size = self.config_classifier.get('bert').get('output_size')\n",
    "\n",
    "        self.labels_output_classifier = self.config_classifier.get('classes')\n",
    "        self.dict_label_index = {label: index for index, label in enumerate(self.labels_output_classifier)}\n",
    "        self.num_labels = len(self.dict_label_index)\n",
    "        # classifier parameters done\n",
    "\n",
    "        self.config_l1 = None\n",
    "        self.l1 = None\n",
    "        self.linear = None\n",
    "\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.loaded = False\n",
    "\n",
    "        self.func_loss = None\n",
    "    # end\n",
    "\n",
    "\n",
    "    def load(self, is_eval=True):\n",
    "        if not self.loaded:\n",
    "            self.config_l1 = BertConfig.from_pretrained(self.path_config_bert)\n",
    "            self.l1 = BertModel(self.config_l1)\n",
    "            self.classifier = torch.nn.Linear(self.classifier_input_size, self.classifier_output_size)\n",
    "            \n",
    "            self.load_state_dict(torch.load(self.path_file_model, map_location=torch.device(self.device)))\n",
    "\n",
    "            print('Please Ignore warning message sent by BertTokenizer below')\n",
    "            self.tokenizer = BertTokenizer.from_pretrained(self.path_folder_model)\n",
    "             \n",
    "            if is_eval:\n",
    "                self.eval()\n",
    "            else:\n",
    "                self.func_loss = torch.nn.CrossEntropyLoss()\n",
    "                self.train()\n",
    "            # end\n",
    "            self.loaded = True\n",
    "        return self\n",
    "    # end\n",
    "\n",
    "    def save(self, path_to_save):\n",
    "        self.tokenizer.save_pretrained(path_to_save)\n",
    "        print('[SUCCESS] tokenizer saved to {}.'.format(path_to_save))\n",
    "\n",
    "        path_to_save_config = os.path.join(path_to_save, self.__class__.DEFAULT_FILENAME_BERT)\n",
    "        with open(path_to_save_config, 'w+') as file:\n",
    "            file.write(self.config_l1.to_json_string())\n",
    "        # end\n",
    "        print('[SUCCESS] l1 config saved to {}.'.format(path_to_save_config))\n",
    "\n",
    "        path_to_save_model = os.path.join(path_to_save, self.__class__.DEFAULT_FILENAME_MODEL)\n",
    "        torch.save(self.state_dict(), path_to_save_model)\n",
    "        print('[SUCCESS] l1 model saved to {}.'.format(path_to_save_model))\n",
    "\n",
    "        path_to_save_classifier = os.path.join(path_to_save, self.__class__.DEFAULT_FILENAME_CLASSIFIER)\n",
    "        with open(path_to_save_classifier, 'w+') as file:\n",
    "            file.write(json.dumps(self.config_classifier))\n",
    "        # end\n",
    "        print('[SUCCESS] classifier config saved to {}.'.format(path_to_save_classifier))\n",
    "    # end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please Ignore warning message sent by BertTokenizer below\n",
      "loaded\n"
     ]
    }
   ],
   "source": [
    "version_model = 'target_v3'\n",
    "\n",
    "path_model = os.path.join('models','bert',version_model)\n",
    "classifier = SimpleBertClassifier(path_model)\n",
    "classifier.load(is_eval=False)\n",
    "print('loaded')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCCESS] tokenizer saved to models\\bert\\target_v4.\n",
      "[SUCCESS] l1 config saved to models\\bert\\target_v4\\bert_config.json.\n",
      "[SUCCESS] l1 model saved to models\\bert\\target_v4\\model.pt.\n",
      "[SUCCESS] classifier config saved to models\\bert\\target_v4\\.model.json.\n"
     ]
    }
   ],
   "source": [
    "version_model_target = version_model[:-1] + str(int(version_model[-1]) + 1)\n",
    "path_model_save = os.path.join('models','bert',version_model_target)\n",
    "os.makedirs(path_model_save, exist_ok=True)\n",
    "\n",
    "classifier.save(path_model_save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
