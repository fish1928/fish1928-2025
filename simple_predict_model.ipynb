{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import BoolTensor\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from scipy.special import softmax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBertClassifier(torch.nn.Module):\n",
    "\n",
    "    DEFAULT_FILENAME_CLASSIFIER = '.model.json'\n",
    "    DEFAULT_FILENAME_BERT = 'bert_config.json'\n",
    "    DEFAULT_FILENAME_MODEL = 'model.pt'\n",
    "    DEFAULT_KEYS_IGNORED_CLASSIFIER = ['metrics', 'allmetrics']\n",
    "\n",
    "    def __init__(self, path_folder_model=None):\n",
    "        super(SimpleBertClassifier, self).__init__()\n",
    "\n",
    "        filename_config_classifier = self.__class__.DEFAULT_FILENAME_CLASSIFIER\n",
    "        filename_config_bert = self.__class__.DEFAULT_FILENAME_BERT\n",
    "        filename_model = self.__class__.DEFAULT_FILENAME_MODEL\n",
    "        keys_ignored_classifier = self .__class__.DEFAULT_KEYS_IGNORED_CLASSIFIER\n",
    "\n",
    "\n",
    "        self.path_folder_model = path_folder_model\n",
    "        self.path_config_bert = os.path.join(path_folder_model, filename_config_bert)\n",
    "        self.path_config_classifier = os.path.join(path_folder_model, filename_config_classifier)\n",
    "        self.path_file_model = os.path.join(path_folder_model, filename_model)\n",
    "\n",
    "        with open(self.path_config_classifier, 'r') as file:\n",
    "            self.config_classifier = json.load(file)\n",
    "        # end\n",
    "\n",
    "        for key in keys_ignored_classifier:\n",
    "            if key in self.config_classifier:\n",
    "                del(self.config_classifier[key])\n",
    "            # end\n",
    "        # end\n",
    "\n",
    "        # classfier parameters\n",
    "        self.classifier_input_size = self.config_classifier.get('bert').get('input_size')\n",
    "        self.classifier_max_length = self.config_classifier.get('bert').get('max_length')\n",
    "        self.classifier_output_size = self.config_classifier.get('bert').get('output_size')\n",
    "\n",
    "        self.labels_output_classifier = self.config_classifier.get('classes')\n",
    "        self.dict_label_index = {label: index for index, label in enumerate(self.labels_output_classifier)}\n",
    "        self.num_labels = len(self.dict_label_index)\n",
    "        # classifier parameters done\n",
    "\n",
    "        self.config_l1 = None\n",
    "        self.l1 = None\n",
    "        self.linear = None\n",
    "\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.loaded = False\n",
    "\n",
    "        self.func_loss = None\n",
    "    # end\n",
    "\n",
    "\n",
    "    def load(self, is_eval=True):\n",
    "        if not self.loaded:\n",
    "            self.config_l1 = BertConfig.from_pretrained(self.path_config_bert)\n",
    "            self.l1 = BertModel(self.config_l1)\n",
    "            self.classifier = torch.nn.Linear(self.classifier_input_size, self.classifier_output_size)\n",
    "            \n",
    "            self.load_state_dict(torch.load(self.path_file_model, map_location=torch.device(self.device)))\n",
    "            self.tokenizer = BertTokenizer.from_pretrained(self.path_folder_model)\n",
    "             \n",
    "            if is_eval:\n",
    "                self.eval()\n",
    "            else:\n",
    "                self.func_loss = torch.nn.CrossEntropyLoss()\n",
    "                self.train()\n",
    "            # end\n",
    "            self.loaded = True\n",
    "        return self\n",
    "    # end\n",
    "\n",
    "    \n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None):\n",
    "        output_bert = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_bert[0]\n",
    "        pooler = hidden_state[:, 0, :]  # only take the CLS one\n",
    "        output = self.classifier(pooler)\n",
    "\n",
    "        if labels is None:\n",
    "            return output\n",
    "        # end\n",
    "\n",
    "        loss = self.func_loss(output.view(-1, self.num_labels), labels.view(-1))\n",
    "        return (loss, output)\n",
    "    # end\n",
    "\n",
    "    def predicts(self, samples_input, need_raw=True):\n",
    "\n",
    "        if type(samples_input) is str:\n",
    "            samples_input = [samples_input]\n",
    "        # end\n",
    "\n",
    "        outputs = []\n",
    "        for sample_input in samples_input:\n",
    "            sentence = ' '.join(sample_input.split())\n",
    "            inputs = self.tokenizer.encode_plus(\n",
    "                sentence, None,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.config_classifier.get('bert').get('max_length'),\n",
    "                padding='max_length',\n",
    "                return_token_type_ids=True,\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "\n",
    "            for key in inputs:\n",
    "                inputs[key].to(self.device)\n",
    "            # end\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = self(**inputs).cpu().numpy().flatten()\n",
    "                outputs.append(output)\n",
    "            # end\n",
    "        # end\n",
    "\n",
    "        labels = self.labels_output_classifier\n",
    "\n",
    "        if need_raw:\n",
    "            info_result = {\n",
    "                'outputs': [output.tolist() for output in outputs],\n",
    "                'labels': labels\n",
    "            }\n",
    "        else:\n",
    "            result_softmax = softmax(np.array(outputs), axis=1)\n",
    "            list_conf = np.amax(result_softmax, axis=1, keepdims=True).reshape(-1).tolist()\n",
    "            list_index_label = np.argmax(result_softmax, axis=1).tolist()\n",
    "            labels_result = [labels[index_label] for index_label in list_index_label]\n",
    "            info_result = {\n",
    "                'outputs': [[conf, label] for conf, label in zip(list_conf, labels_result)],\n",
    "                'labels': None\n",
    "            }\n",
    "        # end\n",
    "        \n",
    "        return info_result\n",
    "    # end\n",
    "\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 loaded\n"
     ]
    }
   ],
   "source": [
    "path_model_1 = os.path.join('models', 'bert', 'target_v1')\n",
    "model_1 = SimpleBertClassifier(path_model_1)\n",
    "model_1.load(is_eval=False)\n",
    "print('model 1 loaded')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(7,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'outputs': [[0.9630028605461121, 'targetvm']], 'labels': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.predicts('hello world', need_raw=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
